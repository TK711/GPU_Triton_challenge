# Day 5: ReLU

## ğŸ“‹ ì‹¤ìŠµ ëª©í‘œ
`max(0, x)` - Rectified Linear Unit êµ¬í˜„

---

## ğŸ“š ì‹¤ìŠµ ì „ ë³µìŠµ ì‚¬í•­

### 1. Day 1-4 ë³µìŠµ
- [ ] ê¸°ë³¸ ì»¤ë„ êµ¬ì¡°
- [ ] `tl.load`, `tl.store` ì‚¬ìš©ë²•
- [ ] Element-wise ì—°ì‚° íŒ¨í„´

### 2. ì¡°ê±´ë¶€ ì—°ì‚° ê°œë…
- [ ] Pythonì˜ `if` ë¬¸ê³¼ëŠ” ë‹¤ë¦„
- [ ] Tritonì€ ë²¡í„°í™”ëœ ì¡°ê±´ë¶€ ì—°ì‚° ì‚¬ìš©

### 3. í•µì‹¬ ê°œë…
```python
# ê¸°ë³¸ êµ¬ì¡°
@triton.jit
def kernel(x_ptr, out_ptr, N, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(0)
    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)
    mask = offsets < N
    
    x = tl.load(x_ptr + offsets, mask=mask)
    # ReLU: max(0, x)
    out = tl.maximum(x, 0.0)  # ë˜ëŠ” tl.where(x > 0, x, 0.0)
    tl.store(out_ptr + offsets, out, mask=mask)
```

---

## ğŸ¯ ì‹¤ìŠµìœ¼ë¡œ ë°°ìš¸ ì‚¬í•­

### 1. ì¡°ê±´ë¶€ ì—°ì‚° ë°©ë²•
- [ ] `tl.maximum(a, b)`: ë‘ ê°’ ì¤‘ í° ê°’ ì„ íƒ
- [ ] `tl.where(condition, x, y)`: ì¡°ê±´ì— ë”°ë¼ ì„ íƒ
- [ ] ë²¡í„°í™”ëœ ì¡°ê±´ë¶€ ì—°ì‚°

### 2. ReLU êµ¬í˜„ ë°©ë²•
```python
# ë°©ë²• 1: tl.maximum ì‚¬ìš©
out = tl.maximum(x, 0.0)

# ë°©ë²• 2: tl.where ì‚¬ìš©
out = tl.where(x > 0, x, 0.0)

# ë°©ë²• 3: ìˆ˜ë™ êµ¬í˜„ (ë¹„íš¨ìœ¨ì )
out = x * (x > 0)  # x > 0ì´ë©´ x, ì•„ë‹ˆë©´ 0
```

### 3. ì„±ëŠ¥ ë¹„êµ
- `tl.maximum`ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ë¹ ë¦„
- `tl.where`ëŠ” ë” ìœ ì—°í•˜ì§€ë§Œ ì•½ê°„ ëŠë¦´ ìˆ˜ ìˆìŒ

---

## âš ï¸ ì£¼ì˜ ì‚¬í•­

### 1. ë°ì´í„° íƒ€ì…
- ì…ë ¥ì´ ìŒìˆ˜ì¼ ìˆ˜ ìˆìŒ
- ì¶œë ¥ì€ í•­ìƒ >= 0
- dtypeì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (float32 â†’ float32)

### 2. 0ì˜ ì²˜ë¦¬
- `x = 0`ì¼ ë•Œ ê²°ê³¼ëŠ” `0`
- `max(0, 0) = 0` ì •í™•íˆ ì²˜ë¦¬

### 3. ë²¡í„°í™”
- `tl.maximum`ì€ ë²¡í„° ì „ì²´ì— ëŒ€í•´ ë™ì‹œì— ì—°ì‚°
- ê° ìš”ì†Œê°€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ë¨

### 4. ë””ë²„ê¹… íŒ
```python
# ë‹¤ì–‘í•œ ì…ë ¥ í…ŒìŠ¤íŠ¸
x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0], device='cuda')
expected = torch.relu(x)  # [0, 0, 0, 1, 2]
result = relu_triton(x)
assert torch.allclose(result, expected)
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Day 1-4 ë³µìŠµ ì™„ë£Œ
- [ ] `tl.maximum` ì‚¬ìš©ë²• ì´í•´
- [ ] `tl.where` ì‚¬ìš©ë²• ì´í•´
- [ ] ReLU êµ¬í˜„ ì™„ë£Œ
- [ ] ì–‘ìˆ˜, ìŒìˆ˜, 0 ê°’ í…ŒìŠ¤íŠ¸
- [ ] PyTorch `torch.relu`ì™€ ë¹„êµ

---

## ğŸ”— ì°¸ê³  ìë£Œ

- Day 1-4 ì½”ë“œ
- PyTorch: `torch.relu()`
- ë‹¤ìŒ Day: Leaky ReLU (ì¡°ê±´ë¶€ ì—°ì‚° í™•ì¥)
