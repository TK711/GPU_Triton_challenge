# Day 8: GeLU

## ğŸ“‹ ì‹¤ìŠµ ëª©í‘œ
GELU Approximation Kernel - ë³µì¡í•œ ìˆ˜í•™ í•¨ìˆ˜ ê·¼ì‚¬ êµ¬í˜„

---

## ğŸ“š ì‹¤ìŠµ ì „ ë³µìŠµ ì‚¬í•­

### 1. Day 7 (Sigmoid) ë³µìŠµ
- [ ] `tl.exp()` ì‚¬ìš©ë²•
- [ ] Numerical stability ê°œë…
- [ ] ë³µì¡í•œ ìˆ˜í•™ í•¨ìˆ˜ êµ¬í˜„ íŒ¨í„´

### 2. ì¡°ê±´ë¶€ ì—°ì‚° (Day 5-6)
- [ ] `tl.where` ì‚¬ìš©ë²•
- [ ] ì¡°ê±´ë¶€ ë¶„ê¸° ì²˜ë¦¬

### 3. Scalar ì—°ì‚°
- [ ] ìƒìˆ˜ ê°’ ì‚¬ìš© (`sqrt(2/Ï€)`, `0.044715` ë“±)

### 4. í•µì‹¬ ê°œë…
```python
# GeLU ê·¼ì‚¬ ê³µì‹
# gelu(x) â‰ˆ 0.5 * x * (1 + tanh(sqrt(2/Ï€) * (x + 0.044715 * x^3)))

@triton.jit
def kernel(x_ptr, out_ptr, N, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(0)
    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)
    mask = offsets < N
    
    x = tl.load(x_ptr + offsets, mask=mask)
    
    # GeLU ê·¼ì‚¬
    sqrt_2_over_pi = 0. # TODO: ê³„ì‚°
    coeff = 0.044715
    # gelu = 0.5 * x * (1 + tanh(...))
    # TODO: êµ¬í˜„
```

---

## ğŸ¯ ì‹¤ìŠµìœ¼ë¡œ ë°°ìš¸ ì‚¬í•­

### 1. GeLU ìˆ˜í•™ì  ì´í•´
- [ ] Gaussian Error Linear Unit
- [ ] ì •ê·œë¶„í¬ì™€ì˜ ê´€ê³„
- [ ] ê·¼ì‚¬ ê³µì‹ ì‚¬ìš© ì´ìœ  (ì •í™•í•œ ê³„ì‚°ì€ ë¹„ìš©ì´ í¼)

### 2. ê·¼ì‚¬(Approximation) ë°©ë²•
- [ ] ì •í™•í•œ GeLUëŠ” ì ë¶„ í¬í•¨ (ê³„ì‚° ë¹„ìš© í¼)
- [ ] Tanh ê¸°ë°˜ ê·¼ì‚¬ ê³µì‹ ì‚¬ìš©
- [ ] ì‹¤ìš©ì ì¸ ì •í™•ë„ì™€ ì„±ëŠ¥ì˜ ê· í˜•

### 3. ë³µì¡í•œ ìˆ˜í•™ í•¨ìˆ˜ êµ¬í˜„
```python
# GeLU ê·¼ì‚¬ ê³µì‹
sqrt_2_over_pi = 0.7978845608  # sqrt(2/Ï€)
coeff = 0.044715

# ì¤‘ê°„ ê³„ì‚°
x_cubed = x * x * x
inner = sqrt_2_over_pi * (x + coeff * x_cubed)
tanh_inner = tl.tanh(inner)

# ìµœì¢… ê²°ê³¼
gelu = 0.5 * x * (1.0 + tanh_inner)
```

### 4. `tl.tanh()` ì‚¬ìš©ë²•
- [ ] Hyperbolic tangent í•¨ìˆ˜
- [ ] ì¶œë ¥ ë²”ìœ„: (-1, 1)
- [ ] `tl.tanh(x)` ì‚¬ìš©

---

## âš ï¸ ì£¼ì˜ ì‚¬í•­

### 1. ìƒìˆ˜ ê°’ ì •í™•ë„
- `sqrt(2/Ï€)` â‰ˆ 0.7978845608
- `0.044715`ëŠ” ì‹¤í—˜ì ìœ¼ë¡œ ê²°ì •ëœ ê°’
- ì •í™•í•œ ê°’ ì‚¬ìš© ì¤‘ìš”

### 2. ìˆ˜ì¹˜ ì•ˆì •ì„±
- `x^3` ê³„ì‚° ì‹œ ì˜¤ë²„í”Œë¡œìš° ê°€ëŠ¥
- í° x ê°’ ì²˜ë¦¬ ì£¼ì˜
- Day 7ì˜ numerical stability ê¸°ë²• ê³ ë ¤

### 3. ê·¼ì‚¬ ì •í™•ë„
- ê·¼ì‚¬ ê³µì‹ì´ë¯€ë¡œ ì™„ë²½í•˜ì§€ ì•ŠìŒ
- ì‹¤ìš©ì ì¸ ë²”ìœ„ì—ì„œ ì¶©ë¶„íˆ ì •í™•
- PyTorchì˜ `torch.nn.GELU()`ì™€ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

### 4. ì„±ëŠ¥
- ì—¬ëŸ¬ ì—°ì‚° ì¡°í•© (ê³±ì…ˆ, ë§ì…ˆ, tanh)
- ìµœì í™” ê°€ëŠ¥í•˜ì§€ë§Œ ìš°ì„  ì •í™•ì„± í™•ì¸

### 5. ë””ë²„ê¹… íŒ
```python
# ë‹¤ì–‘í•œ ì…ë ¥ í…ŒìŠ¤íŠ¸
x = torch.randn(100, device='cuda')

# PyTorch ê²°ê³¼ (ì°¸ê³ ìš©, ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
expected = torch.nn.functional.gelu(x)

result = gelu_triton(x)

# rtolì„ í¬ê²Œ ì„¤ì • (ê·¼ì‚¬ ê³µì‹ì´ë¯€ë¡œ)
assert torch.allclose(result, expected, rtol=1e-2)
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Day 7 (Sigmoid) ë³µìŠµ ì™„ë£Œ
- [ ] GeLU ìˆ˜í•™ì  ì´í•´
- [ ] ê·¼ì‚¬ ê³µì‹ ì´í•´
- [ ] `tl.tanh()` ì‚¬ìš©ë²•
- [ ] GeLU êµ¬í˜„ ì™„ë£Œ
- [ ] ë‹¤ì–‘í•œ ì…ë ¥ ê°’ í…ŒìŠ¤íŠ¸
- [ ] PyTorchì™€ ë¹„êµ (ê·¼ì‚¬ì´ë¯€ë¡œ rtol í¬ê²Œ)

---

## ğŸ”— ì°¸ê³  ìë£Œ

- Day 7 ì½”ë“œ: `../day7/`
- PyTorch: `torch.nn.GELU()`
- ë‹¤ìŒ Day: SiLU (Swish) - Sigmoid ì¬í™œìš©

---

## ğŸ’¡ ì°¸ê³ 

GeLUëŠ” Transformer ëª¨ë¸ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” í™œì„±í™” í•¨ìˆ˜ì…ë‹ˆë‹¤.
ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê·¼ì‚¬ ê³µì‹ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
